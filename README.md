# Interpretable ML
<img src="https://github.com/MaartenGr/InterpretableML/blob/master/Images/lime.PNG" width="70%"/>

> Code and instructions for techniques to improve the explainability of machine learning models.

In this repo, you will find the code and instructions for [this article](https://towardsdatascience.com/opening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e?source=friends_link&sk=55546f17a56c192f4d9f85ab6ccf4005). It is advised to read through the article whilst coding along using the **InterpretableML.ipynb** notebook. 

This repo and the corresponding article describe several methods for applying explainable ML:
* Partial Dependency Plots (PDP)
* Local Interpretable Model-agnostic Explanations (LIME)
* SHapley Additive exPlanations (SHAP)

## Methods
Some methods include: 

### PDP 
<img src="https://github.com/MaartenGr/InterpretableML/blob/master/Images/occupation.png" width="70%"/>

### SHAP
<img src="https://github.com/MaartenGr/InterpretableML/blob/master/Images/shap.PNG" width="70%"/>

### SHAP (Summary)
<img src="https://github.com/MaartenGr/InterpretableML/blob/master/Images/summary_shap.png" width="70%"/>

**To do:**
* Show how you can use SHAP values for deploying models
